{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b62051",
   "metadata": {},
   "source": [
    "This cross-service notebook will walk you through the process of using Textract's DetectDocumenText API to extract text from a JPG/JPEG/PNG file containing text, and then using Comprehend's DetectEntities API to find entities in the extracted text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c62ecb",
   "metadata": {},
   "source": [
    "You can run this notebook using either AWS Sagemaker or Jupyter's NBViewer tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496bef4",
   "metadata": {},
   "source": [
    "### To run this notebook using Sagemaker\n",
    "\n",
    " 1. Navigate to Amazon Sagemaker from the AWS Console. From the Sagemaker dashboard, select Notebook and then choose \"Notebook instances\".\n",
    " 2. Select the optional \"Git repositories\" menu, give the notebook instance a name, and choose the option to \"Clone a public Git repository to this notebook instance only\". \n",
    " 3. In the \"Git repository URL\" box, paste in the URL for this repository (https://github.com/awsdocs/aws-doc-sdk-examples).\n",
    " 4. Select \"Create notebook instance\".\n",
    " 5. You will need to add some policies to your Sagemaker role so it can access S3, Textract, and Comprehend. You can add the following policies to your role: `AmazonTextractFullAccess`, `ComprehendFullAccess`, `AmazonS3ReadOnlyAccess`. \n",
    " 6. After the notebook instance has been created, select it from the list of notebooks. \n",
    " 7. Choose \"Open Jupyter\", and after the Jupyter notebook has started navigate to the directory containing this notebook and select this notebook to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737428bd",
   "metadata": {},
   "source": [
    "### To run this notebook using NBViewer\n",
    "\n",
    "1. Navigate to the NBViewer tool on Jupyter's website (https://nbviewer.jupyter.org/). Paste the URL of this notebook into the text box on the page and select \"Go\".\n",
    "2. On the navigation bar select the Binder symbol to \"Execute on Binder\". After the notebook build you will be able to run the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c58983",
   "metadata": {},
   "source": [
    "In order to make use of the Boto3 Python SDK through NBViewer, you may need to configure your AWS credentials. In the code cell below, replace \"KeyID\" with the value of your AWS Key ID and replace \"AccessKey\" with the value of your AWS Secret Access Key. Do not run the following cell if running this notebook in Sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws configure set aws_access_key_id \"KeyID\"\n",
    "!aws configure set aws_secret_access_key \"AccessKey\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99c2e4",
   "metadata": {},
   "source": [
    "After setting your security credentials, you will need to import any libraries you need. You will also need to set the name of both the S3 bucket you have your image in and the name of the image itself. In the code below, replace the value of \"bucket-name\" with the name of your bucket, replace the value of \"document-name\" with the name of the image file you want to analyze, and replace the value of \"region\" with the name of the region you are operating in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "from PIL import Image               \n",
    "from IPython.display import display \n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "bucket = 'bucket-name'\n",
    "document = 'document-name'\n",
    "region = 'region'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbdf9a",
   "metadata": {},
   "source": [
    "You'll need to create a function that connects to both S3 and Textract via the Boto3 SDK. The function presented in the following code starts by connecting to the S3 resource and retrieving the image you specified from the bucket you specified. The function then connects to Textract and calls the DetectDocumentText API to extract the text in the image. The lines of text found in the document are stored in a list and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the document from S3\n",
    "s3_connection = boto3.resource(\"s3\")\n",
    "    \n",
    "# Connext to Textract to detect text in the document\n",
    "client = boto3.client(\"textract\", region_name=region)\n",
    "\n",
    "# Get the rsponse from S3\n",
    "s3_object = s3_connection.Object(bucket, document)\n",
    "s3_response = s3_object.get()\n",
    "\n",
    "# opening binary stream using an in-memory bytes buffer\n",
    "stream = io.BytesIO(s3_response['Body'].read())\n",
    "\n",
    "# loading stream into image\n",
    "image = Image.open(stream)\n",
    "\n",
    "# Display the image\n",
    "display(image)\n",
    "    \n",
    "def process_text_detection(bucket, document):\n",
    "\n",
    "    # process using S3 object\n",
    "    response = client.detect_document_text(\n",
    "        Document={'S3Object': {'Bucket': bucket, 'Name': document}})\n",
    "\n",
    "    # Get the text blocks\n",
    "    blocks = response['Blocks']\n",
    "\n",
    "    # List to store image lines in document\n",
    "    line_list = []\n",
    "\n",
    "    # Create image showing bounding box/polygon the detected lines/text\n",
    "    for block in blocks:\n",
    "        if block[\"BlockType\"] == \"LINE\":\n",
    "            line_list.append(block[\"Text\"])\n",
    "\n",
    "    return line_list\n",
    "\n",
    "lines = process_text_detection(bucket, document)\n",
    "print(\"Text found: \" + str(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a891bc8",
   "metadata": {},
   "source": [
    "You can now send the lines you extracted from the image to Comprehend and use the service's DetectEntities API to find all entities within those lines. You'll need a function that iterates through the list of lines returned by the \"process_text_detection\" function you wrote earlier and calls the DetectEntities operation on every line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to comprehend\n",
    "comprehend = boto3.client(service_name='comprehend', region_name=region)\n",
    "\n",
    "print('Calling DetectEntities:')\n",
    "print(\"------\")\n",
    "\n",
    "def entity_detection(lines):\n",
    "    \n",
    "    # Create a list to hold the entities found for every line\n",
    "    response_entities = []\n",
    "    \n",
    "    # Iterate through the lines in the list of lines\n",
    "    for line in lines:\n",
    "\n",
    "        # construct a list to hold all found entities for a single line\n",
    "        entities_list = []\n",
    "\n",
    "        # Call the DetectEntities operation and pass it a line from lines\n",
    "        found_entities = comprehend.detect_entities(Text=line, LanguageCode='en')\n",
    "        for response_data, values in found_entities.items():\n",
    "            for item in values:\n",
    "                if \"Text\" in item:\n",
    "                    print(\"Entities found:\")\n",
    "                    for text, val in item.items():\n",
    "                        if text == \"Text\":\n",
    "                            # Append the found entities to the list of entities\n",
    "                            entities_list.append(val)\n",
    "                            print(val)\n",
    "        # Add all found entities for this line to the list of all entities found\n",
    "        response_entities.append(entities_list)\n",
    "\n",
    "    return response_entities\n",
    "\n",
    "response_ents = entity_detection(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca38c9",
   "metadata": {},
   "source": [
    "Now that you have a list of the lines extracted by Textract and the entities found in those lines, you can create a dataframe that lets you see both. In the code below, a Pandas dataframe is constructed, displaying the lines found in the input image and their associated entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_dict = {\"Lines\":lines, \"Entities\":response_ents}\n",
    "df = pd.DataFrame(entities_dict, columns=[\"Lines\",\"Entities\"])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
